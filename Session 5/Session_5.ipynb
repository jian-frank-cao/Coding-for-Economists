{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "057bb604-0cf0-4e18-a164-13e999b0db34",
   "metadata": {},
   "source": [
    "# Coding for Economists - Session 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94440b20-855c-4012-b9e4-f4e0f2094ed6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b7a4bb-545d-4483-8471-a60bed5e3e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install scipy scikit-learn statsmodels -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d553e4e-b9bf-4ef9-90e4-038663ba827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a JSON object.\n",
    "data = {\n",
    "  \"pets\": [\n",
    "    {\n",
    "      \"type\": \"dog\",\n",
    "      \"name\": \"Buddy\",\n",
    "      \"age\": 5,\n",
    "      \"vaccinations\": [\"rabies\", \"distemper\", \"parvovirus\"],\n",
    "      \"owner\": {\n",
    "        \"name\": \"Alice\",\n",
    "        \"contact\": \"alice@example.com\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"cat\",\n",
    "      \"name\": \"Whiskers\",\n",
    "      \"age\": 3,\n",
    "      \"vaccinations\": [\"feline distemper\", \"rabies\"],\n",
    "      \"owner\": {\n",
    "        \"name\": \"Bob\",\n",
    "        \"contact\": \"bob@example.com\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"parrot\",\n",
    "      \"name\": \"Polly\",\n",
    "      \"age\": 2,\n",
    "      \"vaccinations\": [],\n",
    "      \"owner\": {\n",
    "        \"name\": \"Charlie\",\n",
    "        \"contact\": \"charlie@example.com\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40bc32c-7aba-4f8a-a560-609e3e9fde52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pets'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf8a1eb-dd57-40e6-b960-2c750c133e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pets'][1]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10a968-e342-4b87-9ea4-c78ba95c4bac",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1376c0-3d54-434e-8d9c-8bcff9ec9eb0",
   "metadata": {},
   "source": [
    "## 1. Pandas Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b05ab63-cb76-4917-9fa1-711fbb72b766",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112af3a2-9c32-4f82-a690-ad633401a948",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pandas Series (<span style=\"color: green;\">mixed-type</span>, <span style=\"color: blue;\">mutable</span>)\n",
    "- Supports labels (row names)\n",
    "- Automatically match labels when creating a data frame\n",
    "- Please pay attention to __alias__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbff6e3f-58ae-44e2-95e0-c5ce1563cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.Series([1, 2, np.nan, 'a'], index = ['A', 'B', 'C', 'D'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ed5216-1c8e-4f16-863d-2081eea2ecdc",
   "metadata": {},
   "source": [
    "### Pandas DataFrame (<span style=\"color: green;\">mixed-type</span>, <span style=\"color: blue;\">mutable</span>, ideal for data manipulation)\n",
    "- Works swiftly with most data manipulation, analysis, and visualization tools.\n",
    "- Data structure is similar to spreadsheet and Stata. Easy to read.\n",
    "- Please pay attention to __alias__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736f923c-9631-4aed-ac66-cd8ad3a038b9",
   "metadata": {},
   "source": [
    "- __Create pd.DataFrame__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db8d5f8-51ce-4c24-b1c3-6c58038028db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create using a dictionary\n",
    "pets = pd.DataFrame(\n",
    "    {\n",
    "        'Type': ['rabbit', 'fish', 'cat', 'dog'],\n",
    "        'Name': ['Meatball', 'Flash', 'Coco', 'Fluffy'],\n",
    "        'Age': np.random.randint(0, 10, size=(4)),\n",
    "        'Last_visit': pd.date_range('20250210', periods = 4)\n",
    "    }\n",
    ")\n",
    "pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d18a9e-e767-466d-b1a3-6aed0f7340d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create using a np.arrapy\n",
    "daily_return = pd.DataFrame(\n",
    "    np.random.randn(10, 4),\n",
    "    index = pd.date_range('20250210', periods = 10),\n",
    "    columns = ['AAPL', 'GOOG', 'META', 'NVDA']\n",
    ")\n",
    "daily_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659cdf82-d490-4ab1-b705-87fb05d9132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_return.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d90202-fd13-4a4d-a884-25dcc780f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_return.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937750e7-736e-446b-ab31-6a0c7a3ae839",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(daily_return.columns)\n",
    "print(daily_return.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53be0e0-e132-4b23-95a2-e234ab75e8aa",
   "metadata": {},
   "source": [
    "- __Describe__ `.describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64683479-4244-4128-8944-03a1ae8e2832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe data frame\n",
    "daily_return.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494dad2b-288c-4592-944f-272988a4c2b1",
   "metadata": {},
   "source": [
    "- __Indexing__ `.iloc[]`, `.loc[]`, `.at[]`, `.iat[]`, `.COLNAME`, and `[]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e972b0ab-0d5d-4fcb-9c55-15843fb5c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create using a dictionary\n",
    "pets = pd.DataFrame(\n",
    "    {\n",
    "        'Type': ['rabbit', 'fish', 'cat', 'dog'],\n",
    "        'Name': ['Meatball', 'Flash', 'Coco', 'Fluffy'],\n",
    "        'Age': np.random.randint(0, 10, size=(4)),\n",
    "        'Last_visit': pd.date_range('20250210', periods = 4)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Selection by position using .iloc[]   (indices in [] must be integers or :)\n",
    "print(pets.iloc[3, 1])\n",
    "\n",
    "# Selection by label using .loc[]   (indices in [] must be row\\column names or :)\n",
    "print(pets.loc[3, 'Name'])\n",
    "\n",
    "# Get single value by position using .at[] (indices in [] must be integers)\n",
    "print(pets.iat[3, 1])\n",
    "\n",
    "# Get single value by label using .at[] (indices in [] must be row\\column names)\n",
    "print(pets.at[3, 'Name'])\n",
    "\n",
    "# Selection using .COLNAME\n",
    "print(pets.Name[3])\n",
    "\n",
    "# Selection using []\n",
    "print(pets['Name'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2990f78-403b-4c14-b697-8b2750f6c616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean indexing\n",
    "pets[pets['Age'] > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b5bc64-bf7f-4412-b461-15cb44d5f72f",
   "metadata": {},
   "source": [
    "- __Editing Values__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721a281-318f-4269-ba47-8420e81fce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit a single value\n",
    "pets.iloc[3, 0] = 'parrot'\n",
    "pets.loc[3, 'Name'] = 'Polly'\n",
    "pets.at[3, 'Age'] = 35\n",
    "pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f165daa4-eab7-4861-a69b-9b350d782d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit multiple values\n",
    "pets.iloc[1,:3] = ['hamster', 'Buttercup', 3]\n",
    "pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8bf75b-9ff4-4484-a043-78025f595ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit a column\n",
    "pets['Age'] = np.random.randint(0, 10, size=(4))\n",
    "pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82594656-3931-4f06-b859-28f6ab4b201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit using a boolean condition\n",
    "pets.loc[pets['Last_visit'] < '2025-02-12', 'Last_visit'] = pd.to_datetime('2000-01-01')\n",
    "pets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188e934b-d8f7-42cb-a07c-b1540e5658a7",
   "metadata": {},
   "source": [
    "- __Adding Columns and Rows__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6253637-7794-48f5-974f-78afbc49390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6]\n",
    "})\n",
    "\n",
    "# Add a new column 'C'\n",
    "df['C'] = [7, 8, 9]\n",
    "print(\"After adding column 'C':\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a37a48-7d5d-4bc4-afad-cefcd3f1e107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the column 'B'\n",
    "df_drop_col = df.drop('B', axis = 1)\n",
    "print(\"\\nAfter removing column 'B':\")\n",
    "print(df_drop_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75cc27-4eca-4404-9adb-92469fc9ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new row\n",
    "df.loc[3] = [10, 11, 12]\n",
    "print(\"\\nAfter adding a new row with loc:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca3aff2-ed7d-4a5a-a126-886a4f0e9910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first fow\n",
    "df_drop_row = df.drop(0, axis = 0)\n",
    "print(\"\\nAfter removing the first row:\")\n",
    "print(df_drop_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26e764a-2a07-4468-81d9-0fb364e61b5d",
   "metadata": {},
   "source": [
    "- __Merging DataFrames by a Column__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5846168-ac48-4cc2-8fb7-97c2f01f1770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two DataFrames with a common column 'key'\n",
    "df1 = pd.DataFrame({\n",
    "    'key': ['A', 'B', 'C', 'D'],\n",
    "    'value1': [1, 2, 3, 4]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'key': ['B', 'D', 'E', 'F'],\n",
    "    'value2': [5, 6, 7, 8]\n",
    "})\n",
    "\n",
    "# Merge the DataFrames on 'key'\n",
    "# how = ['inner', 'outer', 'left', 'right']\n",
    "merged_df = pd.merge(df1, df2, on='key', how='left')\n",
    "print(\"Merged DataFrame using pd.merge():\")\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde2d51a-a373-497f-8f3f-ca04dfca827c",
   "metadata": {},
   "source": [
    "- __Joining DataFrames by labels (row names)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a8bba9-4ee4-474b-b27a-4c79119971d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two DataFrames with indexes\n",
    "df1 = pd.DataFrame({'value1': [1, 2, 3]}, index=['A', 'B', 'C'])\n",
    "df2 = pd.DataFrame({'value2': [4, 5, 6]}, index=['A', 'B', 'D'])\n",
    "\n",
    "# Join the DataFrames on the index\n",
    "joined_df = df1.join(df2, how='left')\n",
    "print(\"\\nJoined DataFrame using df.join():\")\n",
    "print(joined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6b4b3e-d1cc-4c01-9733-e01443bf5cf5",
   "metadata": {},
   "source": [
    "- __Concating DataFrames__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4077578f-1ffe-4257-bdd8-0d9ac5bd791e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two DataFrames with the same columns\n",
    "df1 = pd.DataFrame({'A': [1, 2], 'B': [3, 4]})\n",
    "df2 = pd.DataFrame({'A': [5, 6], 'B': [7, 8]})\n",
    "\n",
    "# Concatenate vertically\n",
    "vertical_concat = pd.concat([df1, df2], axis=0)\n",
    "print(\"\\nVertical Concatenation using pd.concat():\")\n",
    "print(vertical_concat)\n",
    "\n",
    "# Concatenate horizontally\n",
    "vertical_concat = pd.concat([df1, df2], axis=1)\n",
    "print(\"\\nHorizontal Concatenation using pd.concat():\")\n",
    "print(vertical_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5c65ac-b06b-4979-b33e-74a2fbf227e6",
   "metadata": {},
   "source": [
    "- __Copy on Write__\n",
    "\n",
    "`pd.options.mode.copy_on_write = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e982689-cc2a-4073-9a15-6717e1e9288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame\n",
    "pets = pd.DataFrame(\n",
    "    {\n",
    "        'Type': ['rabbit', 'fish', 'cat', 'dog'],\n",
    "        'Name': ['Meatball', 'Flash', 'Coco', 'Fluffy'],\n",
    "        'Age': np.random.randint(0, 10, size=(4)),\n",
    "        'Last_visit': pd.date_range('20250210', periods = 4)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create an alias\n",
    "pets_new = pets['Type']\n",
    "pets_new.iat[0] = 'tiger'\n",
    "pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d14243c-4529-42a0-8e6e-7d863ec1ce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame\n",
    "pets = pd.DataFrame(\n",
    "    {\n",
    "        'Type': ['rabbit', 'fish', 'cat', 'dog'],\n",
    "        'Name': ['Meatball', 'Flash', 'Coco', 'Fluffy'],\n",
    "        'Age': np.random.randint(0, 10, size=(4)),\n",
    "        'Last_visit': pd.date_range('20250210', periods = 4)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Turn on copy on write\n",
    "pd.options.mode.copy_on_write = True\n",
    "\n",
    "# Create an copy\n",
    "pets_new = pets['Type']\n",
    "pets_new.iat[0] = 'tiger'\n",
    "pets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabff283-cc5e-46f8-bc7e-516ab09b2abb",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947c8b98-c75c-4cc8-af7d-e207088020dc",
   "metadata": {},
   "source": [
    "- __Filtering__ `.filter()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bb8d24-2246-413e-a4db-12bc43c00561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'A_score': [90, 85, 92],\n",
    "    'B_score': [88, 79, 95],\n",
    "    'C_age': [25, 30, 22],\n",
    "    'A_income': [50000, 60000, 55000],\n",
    "    'D_grade': ['A', 'B', 'A']\n",
    "})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e042d2-38f4-4ef5-8c33-6e9f59dd60d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the rows\n",
    "data[data['D_grade'] == 'A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e5ceec-1adc-4f3b-baf1-fbd20fbfb74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the columns that contain a string\n",
    "data.filter(like = 'score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb586ec0-83c3-4cf5-a04e-b88e67f2b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the columns using regular expression \n",
    "data.filter(regex = '^A_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25483ef9-b25d-40f0-bde2-6831d2d2d414",
   "metadata": {},
   "source": [
    "__<span style=\"color: blue;\">Regular Expression Cheat Sheet</span>:__ https://cheatography.com/davechild/cheat-sheets/regular-expressions/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc1c1a-d08b-4482-a9c0-b53dffd87d3b",
   "metadata": {},
   "source": [
    "- __Reshaping__ `.melt()` and `.pivot()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39fd4f5-ce8e-43f8-8733-21cc926e718c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample wide formatDataFrame\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "    'ID': [1, 2, 3],\n",
    "    'year_2019': [10, 20, 30],\n",
    "    'year_2020': [15, 25, 35]\n",
    "}\n",
    ")\n",
    "print(\"Wide Format DataFrame:\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ab686f-855c-4229-ac2c-7ffbdbb4dcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape from wide to long format using melt\n",
    "data_long = pd.melt(data, \n",
    "                  id_vars=['ID'],            # columns to keep fixed\n",
    "                  var_name='Year',           # name of the new variable column\n",
    "                  value_name='Value')        # name of the values column\n",
    "print(\"\\nLong Format DataFrame:\")\n",
    "data_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6d9973-67f8-425c-88a8-4009d50f6bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the long DataFrame back to wide format using pivot\n",
    "data_wide = data_long.pivot(index='ID', columns='Year', values='Value')\n",
    "data_wide.reset_index(inplace=True)  # to bring 'ID' back as a column\n",
    "print(\"\\nPivoted back to Wide Format DataFrame:\")\n",
    "data_wide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21ef11a-0399-4b79-b0d3-724b5d4de998",
   "metadata": {},
   "source": [
    "- __Stacking__ `.stack()` and `.unstack()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2420c09-99d1-44a5-b583-6e64c9ea8a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'A': [1, 2, 3, 4],\n",
    "    'B': [5, 6, 7, 8]\n",
    "}\n",
    "\n",
    "index = pd.date_range('20250218', periods = 4)\n",
    "\n",
    "df = pd.DataFrame(data, index=index)\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78638e8-043e-4d87-8b0d-5a8a446cad14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the DataFrame: turn columns into a new level of the index\n",
    "stacked = df.stack()\n",
    "print(\"\\nStacked DataFrame (Series with a MultiIndex):\")\n",
    "print(stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e58c77-349c-48f5-b0c3-b0f5f450ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index a multiindex dataframe \n",
    "print(stacked.loc[('2025-02-18')])\n",
    "print(stacked.loc[('2025-02-18', 'B')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b07b24-cfeb-485d-ac5d-c3c8733cd1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform multiindex into columns\n",
    "stacked_col = stacked.reset_index()\n",
    "stacked_col.columns = ['time', 'unit', 'value']\n",
    "stacked_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7d0e7f-da93-4021-975d-c4e9836e0b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform columns into multiindex\n",
    "stacked_index = stacked_col.set_index(['time', 'unit'])\n",
    "stacked_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bfef3a-bb2e-47f9-a5ea-3e0bc3a79a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unstack the previously stacked Series to get back to the original DataFrame\n",
    "unstacked = stacked_index.unstack()\n",
    "\n",
    "# This will remove the first level and leave only the second level as the new column names\n",
    "unstacked.columns = unstacked.columns.droplevel(0)\n",
    "unstacked.columns.name = None\n",
    "unstacked.index.name = None\n",
    "\n",
    "print(\"\\nUnstacked DataFrame:\")\n",
    "print(unstacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecadd8e-9162-4b1b-8dae-614eac000217",
   "metadata": {},
   "source": [
    "- __Manipulate Numeric Columns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de17d89a-ed03-484d-8b6b-9737fafb9137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'price': [100, 150, 200, 250],\n",
    "    'quantity': [10, 20, 30, 40]\n",
    "})\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b333ead5-72be-48d7-8154-d6221c1bcc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math operations\n",
    "data['total_value'] = data['price']*data['quantity']\n",
    "data['log_price'] = np.log(data['price'])\n",
    "data['sqrt_price'] = np.sqrt(data['price'])\n",
    "data['sq_quantity'] = np.power(data['quantity'], 2)\n",
    "data['exp_quantity'] = np.exp(data['quantity'])\n",
    "\n",
    "# Standardization\n",
    "data['z_price'] = (data['price'] - data['price'].mean()) / data['price'].std()\n",
    "data['minmax_price'] = (data['price'] - data['price'].min()) / (data['price'].max() - data['price'].min())\n",
    "\n",
    "# create variable using .apply\n",
    "data['price_category'] = data['price'].apply(lambda x: 'high' if x >= 200 else 'low')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e18a2e3-2f91-4885-987c-f67575940041",
   "metadata": {},
   "source": [
    "> __Other Methods:__\n",
    "> - Absolute Value: `np.abs()`\n",
    "> - Round: `np.round()`\n",
    "> - First Difference: `data['col'].diff()`\n",
    "> - Percentage Change: `data['col'].pct_change()`\n",
    "> - Cumulative Sum: `data['col'].cumsum()`\n",
    "> - Cumulative Product: `data['col'].cumprod()`, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc3f0c-a721-4f70-aa31-808db9c79091",
   "metadata": {},
   "source": [
    "- __Manipulate String Columns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b275a10c-2497-4bcf-86eb-78668361864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample DataFrame with string columns\n",
    "data = pd.DataFrame({\n",
    "    'Name': [' Alice ', 'BOB', 'Charlie', 'david'],\n",
    "    'Email': ['Alice@example.com', 'Bob@EXAMPLE.com', 'charlie@example.org', 'DAVID@example.net'],\n",
    "    'Info': ['age: 25; city: New York', 'age:30;city:Los Angeles', 'age: 35; city: Chicago', 'age:40; city:Houston']\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40545fcc-3899-454f-8525-38b127d11117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert strings to lowercase and uppercase\n",
    "data['Name_lower'] = data['Name'].str.lower()\n",
    "data['Email_upper'] = data['Email'].str.upper()\n",
    "\n",
    "# Remove leading/trailing whitespace\n",
    "data['Name_stripped'] = data['Name'].str.strip()\n",
    "\n",
    "# Replace or remove substrings\n",
    "# Remove the domain from Email addresses\n",
    "data['Email_no_domain'] = data['Email'].str.replace(r'@.*', '', regex=True)\n",
    "\n",
    "# Splitting strings\n",
    "# Split 'Info' column on semicolon and expand into separate columns\n",
    "data[['Info_part1', 'Info_part2']] = data['Info'].str.split(';', expand=True)\n",
    "\n",
    "# Extract patterns using regex\n",
    "# Extract the age number from the Info column\n",
    "data['Age'] = data['Info'].str.extract(r'age:\\s*(\\d+)', expand=False).astype(int)\n",
    "\n",
    "# Concatenate string columns\n",
    "# Combine the stripped Name and Email_no_domain into a new identifier column\n",
    "data['Identifier1'] = data['Name_stripped'] + '_' + data['Email_no_domain']\n",
    "data['Identifier2'] = data['Name_stripped'].str.cat(data['Email_no_domain'], sep=\"_\", na_rep=\"-\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f387d54e-5721-454f-8fb5-4d016ce52082",
   "metadata": {},
   "source": [
    "> __Other Methods:__\n",
    "> - Length: `data['col'].str.len()`\n",
    "> - Stripe Whitespaces: `data['col'].str.strip()`, `data['col'].str.lstrip()`, `data['col'].str.rstrip()`\n",
    "> - Remove prefix/suffix: `data['col'].str.removeprefix('str_')`, `data['col'].str.removesuffix('_str')`\n",
    "> - Contain: `data['col'].str.contain('str')`\n",
    "> - Match: `data['col'].str.match('str')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20391120-e041-4b5c-8e8a-acc4d241b619",
   "metadata": {},
   "source": [
    "- __Handle Duplicates__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9236858-1490-498f-a8eb-74e572f87dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'A': [1, 2, 2, 3, 4, 4, 4],\n",
    "    'B': ['x', 'y', 'y', 'z', 'w', 'w', 'w']\n",
    "})\n",
    "print(\"Original DataFrame:\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485c0386-3006-4a48-9290-2d4197376eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect duplicate rows (by default, it marks all rows except the first occurrence as duplicates)\n",
    "duplicates = data.duplicated()\n",
    "print(\"\\nBoolean Series indicating duplicates:\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc46dcd6-15fa-456d-9506-056f95c542b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates and keep the first occurrence\n",
    "data_no_duplicates = data.drop_duplicates()\n",
    "print(\"\\nDataFrame after dropping duplicates:\")\n",
    "print(data_no_duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed530e4-94d2-4ada-9463-881166479a33",
   "metadata": {},
   "source": [
    "- __Handle Outliers__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f10cea-f117-4589-a226-272785855d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'value': [10, 12, 15, 14, 18, 200, 13, 15, 16, 100]\n",
    "})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d4f280-d1d8-44c2-b6d5-66520a033ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The IQR Method\n",
    "# Calculate Q1, Q3, and IQR\n",
    "Q1 = data['value'].quantile(0.25)\n",
    "Q3 = data['value'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define outlier bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Detect outliers\n",
    "outliers = data[(data['value'] < lower_bound) | (data['value'] > upper_bound)]\n",
    "print(\"Outliers detected using IQR method:\")\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994bceb2-8627-47b2-8090-34f01a90fee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling outliers:\n",
    "# Option A: Investigate the reason and fix the outliers\n",
    "\n",
    "# Option B: Drop outliers\n",
    "data_no_outliers = data[(data['value'] >= lower_bound) & (data['value'] <= upper_bound)]\n",
    "print(\"\\nDataFrame after dropping outliers:\")\n",
    "print(data_no_outliers)\n",
    "\n",
    "# Option C: Cap outliers (Winsorization)\n",
    "data['value_capped'] = data['value'].clip(lower=lower_bound, upper=upper_bound)\n",
    "print(\"\\nDataFrame with outliers capped:\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5287a6f7-8c9b-49ba-9891-63f58f2cce69",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Z-score Method\n",
    "# Sample DataFrame\n",
    "data = pd.DataFrame(\n",
    "    np.random.randn(50, 1),\n",
    "    columns = ['value']\n",
    ")\n",
    "data.iat[3,0] = 99999\n",
    "\n",
    "# Calculate mean and standard deviation\n",
    "mean_val = data['value'].mean()\n",
    "std_val = data['value'].std()\n",
    "\n",
    "# Compute z-scores\n",
    "data['z_score'] = (data['value'] - mean_val) / std_val\n",
    "\n",
    "# Detect outliers: typically |z| > 3\n",
    "outliers_z = data[np.abs(data['z_score']) > 3]\n",
    "print(\"Outliers detected using z-scores:\")\n",
    "print(outliers_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b31824-05a2-4e04-9f4e-87d79ad0060c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling outliers:\n",
    "# Option A: Investigate the reason and fix the outliers\n",
    "\n",
    "# Option B: Remove outliers\n",
    "data_no_outliers_z = data[np.abs(data['z_score']) <= 3].copy()\n",
    "print(\"\\nDataFrame after dropping outliers based on z-scores:\")\n",
    "data_no_outliers_z.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527123e1-598d-4636-8e22-147f1a227d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option C: Replace extreme values with boundary values\n",
    "data['value_capped'] = np.where(\n",
    "    data['z_score'] > 3,\n",
    "    mean_val + 3 * std_val,\n",
    "    np.where(data['z_score'] < -3, mean_val - 3 * std_val, data['value'])\n",
    ")\n",
    "print(\"\\nDataFrame with capped values based on z-scores:\")\n",
    "data[['value', 'value_capped']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100d29e5-5718-4b45-ba68-8a52b6249920",
   "metadata": {},
   "source": [
    "## 3. Missing Data\n",
    "  - __MCAR__: Listwise Deletion, Fill Mean\n",
    "  - __MAR__: KNN Imputation, Multiple Imputation\n",
    "  - __MNAR__: More Data, Selection Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90805eaa-a94d-4405-b7f6-d3336b2befe4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### MCAR Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6020cd1-c34f-4ba0-aef8-96685acf4026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Little's MCAR Test (NULL hypothesis: missing data are MCAR)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "def little_mcar_test(data):\n",
    "    \"\"\"\n",
    "    Perform Little's MCAR test on a pandas DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The dataset to test.\n",
    "        \n",
    "    Returns:\n",
    "        test_stat (float): The computed test statistic.\n",
    "        df_total (int): Total degrees of freedom.\n",
    "        p_value (float): p-value for the test.\n",
    "    \"\"\"\n",
    "    # Create a boolean DataFrame indicating missingness\n",
    "    missing = data.isnull()\n",
    "    \n",
    "    # Identify unique missingness patterns as tuples\n",
    "    pattern_keys = missing.drop_duplicates().apply(lambda row: tuple(row), axis=1)\n",
    "    \n",
    "    # Map each row in the data to its missingness pattern (as a tuple)\n",
    "    group_indices = {}\n",
    "    for idx, row in missing.iterrows():\n",
    "        pattern = tuple(row)\n",
    "        group_indices.setdefault(pattern, []).append(idx)\n",
    "        \n",
    "    overall_means = data.mean()\n",
    "    test_stat = 0.0\n",
    "    df_total = 0\n",
    "    \n",
    "    # Loop over each missingness pattern group\n",
    "    for pattern, indices in group_indices.items():\n",
    "        group_data = data.loc[indices]\n",
    "        # Determine which columns are observed (i.e. not missing) in this pattern\n",
    "        observed_cols = [col for col, missing_flag in zip(data.columns, pattern) if not missing_flag]\n",
    "        n_group = len(group_data)\n",
    "        # Only consider groups with at least one observed variable\n",
    "        if n_group == 0 or len(observed_cols) == 0:\n",
    "            continue\n",
    "        # Mean for this group (only for observed variables)\n",
    "        group_mean = group_data[observed_cols].mean()\n",
    "        # Covariance matrix for the observed variables in this group\n",
    "        group_cov = group_data[observed_cols].cov()\n",
    "        # Difference between group means and overall means for the observed variables\n",
    "        diff = group_mean - overall_means[observed_cols]\n",
    "        \n",
    "        # Compute the inverse of the covariance matrix; if singular, use pseudo-inverse\n",
    "        try:\n",
    "            inv_cov = np.linalg.inv(group_cov)\n",
    "        except np.linalg.LinAlgError:\n",
    "            inv_cov = np.linalg.pinv(group_cov)\n",
    "        \n",
    "        # Compute the quadratic form for the test statistic contribution of this group\n",
    "        stat = n_group * diff.T.dot(inv_cov).dot(diff)\n",
    "        test_stat += stat\n",
    "        \n",
    "        # Degrees of freedom is the number of observed variables for this pattern\n",
    "        df_total += len(observed_cols)\n",
    "    \n",
    "    p_value = 1 - stats.chi2.cdf(test_stat, df_total)\n",
    "    return test_stat, df_total, p_value\n",
    "\n",
    "# -------------------------\n",
    "# Example usage:\n",
    "# -------------------------\n",
    "np.random.seed(0)\n",
    "\n",
    "# Create a sample dataset with three variables.\n",
    "data = pd.DataFrame({\n",
    "    'x': np.random.randn(100),\n",
    "    'y': np.random.randn(100),\n",
    "    'z': np.random.randn(100)\n",
    "})\n",
    "\n",
    "# Introduce missingness completely at random (MCAR) in 'y'\n",
    "mask = np.random.rand(100) < 0.3  # 30% missing at random\n",
    "data.loc[mask, 'y'] = np.nan\n",
    "\n",
    "# Run Little's MCAR test\n",
    "test_stat, df_val, p_val = little_mcar_test(data)\n",
    "print(\"Little's MCAR test statistic:\", test_stat)\n",
    "print(\"Degrees of freedom:\", df_val)\n",
    "print(\"p-value:\", p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7289ea-0801-4244-9b00-a71ca1f0d111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the missing values\n",
    "data.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c5fd7f-e5a9-4e68-a5d3-5493fb7ebbfe",
   "metadata": {},
   "source": [
    "### Listwise Deletion (Drop missing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c7203d-a793-4732-8045-fb05be2d0475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data Frame\n",
    "np.random.seed(0)\n",
    "\n",
    "# Create a sample dataset with three variables.\n",
    "data = pd.DataFrame({\n",
    "    'x': np.random.randn(100),\n",
    "    'y': np.random.randn(100),\n",
    "    'z': np.random.randn(100)\n",
    "})\n",
    "\n",
    "# Introduce missingness completely at random (MCAR) in 'y'\n",
    "mask = np.random.rand(100) < 0.3  # 30% missing at random\n",
    "data.loc[mask, 'y'] = np.nan\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f717401a-5f99-4835-aa87-d78334635b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with missing data\n",
    "data_drop_row = data.dropna()\n",
    "data_drop_row.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa08bab6-c2a6-4478-bcd1-13bee898dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns with missing data\n",
    "data_drop_row = data.dropna(axis = 1)\n",
    "data_drop_row.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8207421f-b0f0-40e1-b214-0aee24d4bc1d",
   "metadata": {},
   "source": [
    "### Fill Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd4c39-9fd0-4577-8362-c3f61856056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data Frame\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        'A': [1, 2, np.nan, 5, 6, 7],\n",
    "        'B': [0.25, np.nan, np.nan, 3, 10, 15]\n",
    "    }\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d72c50-6ec2-4cab-a6f5-f484b741d658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with column means\n",
    "data.fillna(data.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a380bb-94d7-4f66-a8f7-e131d6abd68d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Fill Forward/backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41cb92d-31f7-4c2b-9f4d-e6302058d22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data Frame\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        'A': [1, 2, np.nan, 5, 6, 7],\n",
    "        'B': [0.25, np.nan, np.nan, 3, 10, 15]\n",
    "    }\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9609fe-7c08-4c9f-8b6e-14b0113ce527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill forward\n",
    "data.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf76c8b3-1981-4d02-8bbe-185b2941f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill backward\n",
    "data.bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c76bd8-c1b0-4ffb-abbe-93441e1152b7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18495345-9d56-4e77-a2db-13be9f32a2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Data Frame\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "        'A': [1, 2, np.nan, 5, 6, 7],\n",
    "        'B': [0.25, np.nan, np.nan, 3, 10, 15]\n",
    "    }\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830e59fb-4177-4143-9d1a-829af35e3005",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3685d4af-9abf-43a1-83fc-643c90da1924",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (KNN) Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def6611-ed94-4c5d-9115-e0789f447483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "# Create a sample DataFrame with missing values\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "    'age': [25, np.nan, 30, 22, np.nan, 28, 35],\n",
    "    'income': [50000, 60000, np.nan, 52000, 58000, np.nan, 75000]\n",
    "    }\n",
    ")\n",
    "print(\"Original DataFrame:\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b99cc-b997-46f9-b2b6-a4f1f4a8515f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the KNNImputer with k=2 neighbors and uniform weighting\n",
    "imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "\n",
    "# Fit the imputer on X and transform the data\n",
    "data_imputed = imputer.fit_transform(data)\n",
    "\n",
    "# Transform to pd.DataFrame\n",
    "data_imputed = pd.DataFrame(data_imputed)\n",
    "\n",
    "print('Imputed DataFrame')\n",
    "data_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf9c42-ced7-4ff0-bc1f-8d9961ee49ad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Multiple Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf2d4b9-83a9-47a3-9b79-2a34836f69f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.imputation.mice import MICEData\n",
    "\n",
    "# Create a simple DataFrame with missing values\n",
    "data = pd.DataFrame(\n",
    "    {\n",
    "    'age': [25, np.nan, 30, 22, np.nan, 28, 35],\n",
    "    'income': [50000, 60000, np.nan, 52000, 58000, np.nan, 75000]\n",
    "    }\n",
    ")\n",
    "print(\"Original Data:\")\n",
    "print(data)\n",
    "\n",
    "# Initialize MICEData instance for multiple imputation\n",
    "mice_data = MICEData(data)\n",
    "\n",
    "# Generate multiple imputed datasets\n",
    "imputed_datasets = []\n",
    "num_imputations = 5  # number of imputed datasets to generate\n",
    "\n",
    "for i in range(num_imputations):\n",
    "    # Update imputed values for all missing entries (one MICE iteration)\n",
    "    mice_data.update_all()\n",
    "    # Store a copy of the complete dataset\n",
    "    imputed_datasets.append(mice_data.data.copy())\n",
    "\n",
    "# Display one of the imputed datasets\n",
    "print(\"\\nOne of the imputed datasets:\")\n",
    "print(imputed_datasets[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e740b91f-872c-4800-af54-26f6f7b24f08",
   "metadata": {},
   "source": [
    "__Work with Multiple Imputed Data__\n",
    "- Perform analysis independently on each imputed dataset.\n",
    "- Pool the results using Rubin's Rules: https://bookdown.org/mwheymans/bookmi/rubins-rules.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c98215-2cf7-483e-afde-76ff0eb56b2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
