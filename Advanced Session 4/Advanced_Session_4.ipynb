{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "287ce01a-1e6c-4019-8706-ffedab51322c",
   "metadata": {},
   "source": [
    "# Coding for Economists - Advanced Session 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7daa3c-fd9a-44e1-aa25-ec7b0ae40451",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d01759f-34b6-455d-9c92-546720c8a333",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install line-profiler memory-profiler dask 'dask[distributed]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b55e855-0e4f-4fb5-a65a-8dd3e049c778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install in Google Colab\n",
    "# !pip install line-profiler memory-profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce99a9a1-b0bd-434b-8bca-047437a1b625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Turn on copy on write\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c1a8bd1-4035-46ba-bda8-f946d9185db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load profilers\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c65a212-c43a-4234-98d4-bba1404b1eb2",
   "metadata": {},
   "source": [
    "## 2. A Slow Application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f87910-bb1b-464e-8d6b-2a42e049ff6d",
   "metadata": {},
   "source": [
    "### 2.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6f52f3e0-be0f-4c18-a381-8288f3bedb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['AFG', 'AGO', 'ALB', 'ARE', 'ARG', 'ARM', 'ATG', 'AUS', 'AUT', 'AZE', 'BDI', 'BEL', 'BEN', 'BFA', 'BGD', 'BGR', 'BHR', 'BHS', 'BIH', 'BLR', 'BLZ', 'BOL', 'BRA', 'BRB', 'BRN', 'BTN', 'BWA', 'CAF', 'CAN', 'CHE', 'CHL', 'CHN', 'CIV', 'CMR', 'COD', 'COG', 'COL', 'COM', 'CPV', 'CRI', 'CYP', 'CZE', 'DEU', 'DJI', 'DMA', 'DNK', 'DOM', 'DZA', 'ECU', 'EGY', 'ERI', 'ESP', 'EST', 'ETH', 'FIN', 'FJI', 'FRA', 'FSM', 'GAB', 'GBR', 'GEO', 'GHA', 'GIN', 'GMB', 'GNB', 'GNQ', 'GRC', 'GRD', 'GTM', 'GUY', 'HKG', 'HND', 'HRV', 'HTI', 'HUN', 'IDN', 'IND', 'IRL', 'IRN', 'IRQ', 'ISL', 'ISR', 'ITA', 'JAM', 'JOR', 'JPN', 'KAZ', 'KEN', 'KGZ', 'KHM', 'KIR', 'KNA', 'KOR', 'KWT', 'LAO', 'LBN', 'LBR', 'LBY', 'LCA', 'LKA', 'LSO', 'LTU', 'LUX', 'LVA', 'MAR', 'MDA', 'MDG', 'MDV', 'MEX', 'MHL', 'MKD', 'MLI', 'MLT', 'MMR', 'MNE', 'MNG', 'MOZ', 'MRT', 'MUS', 'MWI', 'MYS', 'NAM', 'NER', 'NGA', 'NIC', 'NLD', 'NOR', 'NPL', 'NZL', 'OMN', 'PAK', 'PAN', 'PER', 'PHL', 'PLW', 'PNG', 'POL', 'PRT', 'PRY', 'QAT', 'ROU', 'RUS', 'RWA', 'SAU', 'SDN', 'SEN', 'SGP', 'SLB', 'SLE', 'SLV', 'SMR', 'SRB', 'SSD', 'STP', 'SUR', 'SVK', 'SVN', 'SWE', 'SWZ', 'SYC', 'SYR', 'TCD', 'TGO', 'THA', 'TJK', 'TKM', 'TLS', 'TON', 'TTO', 'TUN', 'TUR', 'TUV', 'TWN', 'TZA', 'UGA', 'UKR', 'URY', 'USA', 'UVK', 'UZB', 'VCT', 'VEN', 'VNM', 'VUT', 'WSM', 'YEM', 'ZAF', 'ZMB', 'ZWE'])\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "gdp = {}\n",
    "path = 'gdp_panel.csv'\n",
    "with open(path) as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        country = row['code']\n",
    "        value = float(row['value'])\n",
    "        if country not in gdp:\n",
    "            gdp[country] = []\n",
    "        gdp[country].append(value)\n",
    "\n",
    "regions = {}\n",
    "path = 'country_region.csv'\n",
    "with open(path) as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        country = row['code']\n",
    "        region = row['region']\n",
    "        if country not in regions:\n",
    "            regions[country] = region\n",
    "\n",
    "print(gdp.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ccda0100-9e7a-421b-b720-d265417ad130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Europe\n"
     ]
    }
   ],
   "source": [
    "print(regions['IRL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2156a91-441a-4702-8044-35cfc838adfc",
   "metadata": {},
   "source": [
    "### 2.2 Compute GDP Growth and Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7fc3fffd-bf6b-4c66-bbe4-101d5558fd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['AFG', 'AGO', 'ALB', 'ARE', 'ARG', 'ARM', 'ATG', 'AUS', 'AUT', 'AZE', 'BDI', 'BEL', 'BEN', 'BFA', 'BGD', 'BGR', 'BHR', 'BHS', 'BIH', 'BLR', 'BLZ', 'BOL', 'BRA', 'BRB', 'BRN', 'BTN', 'BWA', 'CAF', 'CAN', 'CHE', 'CHL', 'CHN', 'CIV', 'CMR', 'COD', 'COG', 'COL', 'COM', 'CPV', 'CRI', 'CYP', 'CZE', 'DEU', 'DJI', 'DMA', 'DNK', 'DOM', 'DZA', 'ECU', 'EGY', 'ERI', 'ESP', 'EST', 'ETH', 'FIN', 'FJI', 'FRA', 'FSM', 'GAB', 'GBR', 'GEO', 'GHA', 'GIN', 'GMB', 'GNB', 'GNQ', 'GRC', 'GRD', 'GTM', 'GUY', 'HKG', 'HND', 'HRV', 'HTI', 'HUN', 'IDN', 'IND', 'IRL', 'IRN', 'IRQ', 'ISL', 'ISR', 'ITA', 'JAM', 'JOR', 'JPN', 'KAZ', 'KEN', 'KGZ', 'KHM', 'KIR', 'KNA', 'KOR', 'KWT', 'LAO', 'LBN', 'LBR', 'LBY', 'LCA', 'LKA', 'LSO', 'LTU', 'LUX', 'LVA', 'MAR', 'MDA', 'MDG', 'MDV', 'MEX', 'MHL', 'MKD', 'MLI', 'MLT', 'MMR', 'MNE', 'MNG', 'MOZ', 'MRT', 'MUS', 'MWI', 'MYS', 'NAM', 'NER', 'NGA', 'NIC', 'NLD', 'NOR', 'NPL', 'NZL', 'OMN', 'PAK', 'PAN', 'PER', 'PHL', 'PLW', 'PNG', 'POL', 'PRT', 'PRY', 'QAT', 'ROU', 'RUS', 'RWA', 'SAU', 'SDN', 'SEN', 'SGP', 'SLB', 'SLE', 'SLV', 'SMR', 'SRB', 'SSD', 'STP', 'SUR', 'SVK', 'SVN', 'SWE', 'SWZ', 'SYC', 'SYR', 'TCD', 'TGO', 'THA', 'TJK', 'TKM', 'TLS', 'TON', 'TTO', 'TUN', 'TUR', 'TUV', 'TWN', 'TZA', 'UGA', 'UKR', 'URY', 'USA', 'UVK', 'UZB', 'VCT', 'VEN', 'VNM', 'VUT', 'WSM', 'YEM', 'ZAF', 'ZMB', 'ZWE'])\n"
     ]
    }
   ],
   "source": [
    "from statistics import pstdev\n",
    "\n",
    "metrics = {}\n",
    "window = 52\n",
    "for country, series in gdp.items():\n",
    "    growth = []\n",
    "    vol = []\n",
    "    for i in range(window, len(series)):\n",
    "        prev = series[i-window]\n",
    "        curr = series[i]\n",
    "        growth.append((curr - prev) / prev)\n",
    "        vol.append(pstdev(series[i-window:i]))\n",
    "    metrics[country] = {'growth': growth, 'vol': vol}\n",
    "\n",
    "print(metrics.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea1fbec-48a7-48d5-8b22-a95fdd70c56f",
   "metadata": {},
   "source": [
    "### 2.3 Aggregate Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "68a2130e-aa1e-4b66-bd00-58474ddafec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Asia': {'avg_growth': 0.04330520206247363, 'avg_vol': 2574.585938176005}, 'Africa': {'avg_growth': 0.03458519294974054, 'avg_vol': 39.16879991869174}, 'Europe': {'avg_growth': 0.01903380340329299, 'avg_vol': 33.2089496557581}, 'South America': {'avg_growth': 0.02698163863184202, 'avg_vol': 328.9790282587653}, 'North America': {'avg_growth': 0.025703795612439923, 'avg_vol': 8.29425195157262}, 'Oceania': {'avg_growth': 0.019067501900675687, 'avg_vol': 0.8709104509906413}}\n"
     ]
    }
   ],
   "source": [
    "# country → region\n",
    "agg = {}  # plain dict\n",
    "\n",
    "# Collect all growth & vol values by region\n",
    "for country, m in metrics.items():\n",
    "    region = regions[country]\n",
    "    if region not in agg:\n",
    "        agg[region] = {'growth': [], 'vol': []}\n",
    "    agg[region]['growth'].extend(m['growth'])\n",
    "    agg[region]['vol'].extend(m['vol'])\n",
    "\n",
    "# Compute regional averages\n",
    "result = {}\n",
    "for region, d in agg.items():\n",
    "    total_growth = sum(d['growth'])\n",
    "    total_vol    = sum(d['vol'])\n",
    "    count_growth = len(d['growth'])\n",
    "    count_vol    = len(d['vol'])\n",
    "    result[region] = {\n",
    "        'avg_growth': total_growth / count_growth if count_growth else 0,\n",
    "        'avg_vol':    total_vol    / count_vol    if count_vol    else 0\n",
    "    }\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb97a329-9a08-4b0e-a4fa-7bb1410ed64c",
   "metadata": {},
   "source": [
    "### 2.4 Time and Memory Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3fc2de8a-8e4c-483a-9092-e029045447e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 21.4275 s\n",
       "File: /var/folders/j4/72zz472s4sdd1r1ssyml8k5w0000gn/T/ipykernel_30612/3544963303.py\n",
       "Function: run_analysis_v0 at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def run_analysis_v0():\n",
       "     2                                               # Load Data\n",
       "     3         1       1000.0   1000.0      0.0      gdp = {}\n",
       "     4         1          0.0      0.0      0.0      path = 'gdp_panel.csv'\n",
       "     5         2     509000.0 254500.0      0.0      with open(path) as f:\n",
       "     6         1      16000.0  16000.0      0.0          reader = csv.DictReader(f)\n",
       "     7    359997  429302000.0   1192.5      2.0          for row in reader:\n",
       "     8    359996   21779000.0     60.5      0.1              country = row['code']\n",
       "     9    359996   60667000.0    168.5      0.3              value = float(row['value'])\n",
       "    10    359996   24662000.0     68.5      0.1              if country not in gdp:\n",
       "    11       189      40000.0    211.6      0.0                  gdp[country] = []\n",
       "    12    359996   26564000.0     73.8      0.1              gdp[country].append(value)\n",
       "    13                                           \n",
       "    14         1          0.0      0.0      0.0      regions = {}\n",
       "    15         1          0.0      0.0      0.0      path = 'country_region.csv'\n",
       "    16         2      66000.0  33000.0      0.0      with open(path) as f:\n",
       "    17         1       7000.0   7000.0      0.0          reader = csv.DictReader(f)\n",
       "    18       272     483000.0   1775.7      0.0          for row in reader:\n",
       "    19       271      17000.0     62.7      0.0              country = row['code']\n",
       "    20       271      18000.0     66.4      0.0              region = row['region']\n",
       "    21       271      24000.0     88.6      0.0              if country not in regions:\n",
       "    22       258      26000.0    100.8      0.0                  regions[country] = region\n",
       "    23                                           \n",
       "    24                                               # Compute dgp growth rate and volitility\n",
       "    25         1          0.0      0.0      0.0      metrics = {}\n",
       "    26         1       1000.0   1000.0      0.0      window = 52\n",
       "    27       190      34000.0    178.9      0.0      for country, series in gdp.items():\n",
       "    28       189      18000.0     95.2      0.0          growth = []\n",
       "    29       189      13000.0     68.8      0.0          vol = []\n",
       "    30    350357   27921000.0     79.7      0.1          for i in range(window, len(series)):\n",
       "    31    350168   23301000.0     66.5      0.1              prev = series[i-window]\n",
       "    32    350168   19307000.0     55.1      0.1              curr = series[i]\n",
       "    33    350168   29203000.0     83.4      0.1              growth.append((curr - prev) / prev)\n",
       "    34    350168        2e+10  59281.3     96.9              vol.append(pstdev(series[i-window:i]))\n",
       "    35       189      78000.0    412.7      0.0          metrics[country] = {'growth': growth, 'vol': vol}\n",
       "    36                                           \n",
       "    37                                               # Aggregate Regions\n",
       "    38         1          0.0      0.0      0.0      agg = {}  # plain dict\n",
       "    39                                           \n",
       "    40       190      24000.0    126.3      0.0      for country, m in metrics.items():\n",
       "    41       189      23000.0    121.7      0.0          region = regions[country]\n",
       "    42       189      14000.0     74.1      0.0          if region not in agg:\n",
       "    43         6          0.0      0.0      0.0              agg[region] = {'growth': [], 'vol': []}\n",
       "    44       189    2493000.0  13190.5      0.0          agg[region]['growth'].extend(m['growth'])\n",
       "    45       189    1083000.0   5730.2      0.0          agg[region]['vol'].extend(m['vol'])\n",
       "    46                                           \n",
       "    47         1          0.0      0.0      0.0      result = {}\n",
       "    48         7       2000.0    285.7      0.0      for region, d in agg.items():\n",
       "    49         6     710000.0 118333.3      0.0          total_growth = sum(d['growth'])\n",
       "    50         6     668000.0 111333.3      0.0          total_vol    = sum(d['vol'])\n",
       "    51         6       1000.0    166.7      0.0          count_growth = len(d['growth'])\n",
       "    52         6       1000.0    166.7      0.0          count_vol    = len(d['vol'])\n",
       "    53         6       2000.0    333.3      0.0          result[region] = {\n",
       "    54         6       1000.0    166.7      0.0              'avg_growth': total_growth / count_growth if count_growth else 0,\n",
       "    55         6          0.0      0.0      0.0              'avg_vol':    total_vol    / count_vol    if count_vol    else 0\n",
       "    56                                                   }\n",
       "    57         1       2000.0   2000.0      0.0      return result"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_analysis_v0():\n",
    "    # Load Data\n",
    "    gdp = {}\n",
    "    path = 'gdp_panel.csv'\n",
    "    with open(path) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            country = row['code']\n",
    "            value = float(row['value'])\n",
    "            if country not in gdp:\n",
    "                gdp[country] = []\n",
    "            gdp[country].append(value)\n",
    "    \n",
    "    regions = {}\n",
    "    path = 'country_region.csv'\n",
    "    with open(path) as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            country = row['code']\n",
    "            region = row['region']\n",
    "            if country not in regions:\n",
    "                regions[country] = region\n",
    "\n",
    "    # Compute dgp growth rate and volitility\n",
    "    metrics = {}\n",
    "    window = 52\n",
    "    for country, series in gdp.items():\n",
    "        growth = []\n",
    "        vol = []\n",
    "        for i in range(window, len(series)):\n",
    "            prev = series[i-window]\n",
    "            curr = series[i]\n",
    "            growth.append((curr - prev) / prev)\n",
    "            vol.append(pstdev(series[i-window:i]))\n",
    "        metrics[country] = {'growth': growth, 'vol': vol}\n",
    "\n",
    "    # Aggregate Regions\n",
    "    agg = {}  # plain dict\n",
    "\n",
    "    for country, m in metrics.items():\n",
    "        region = regions[country]\n",
    "        if region not in agg:\n",
    "            agg[region] = {'growth': [], 'vol': []}\n",
    "        agg[region]['growth'].extend(m['growth'])\n",
    "        agg[region]['vol'].extend(m['vol'])\n",
    "    \n",
    "    result = {}\n",
    "    for region, d in agg.items():\n",
    "        total_growth = sum(d['growth'])\n",
    "        total_vol    = sum(d['vol'])\n",
    "        count_growth = len(d['growth'])\n",
    "        count_vol    = len(d['vol'])\n",
    "        result[region] = {\n",
    "            'avg_growth': total_growth / count_growth if count_growth else 0,\n",
    "            'avg_vol':    total_vol    / count_vol    if count_vol    else 0\n",
    "        }\n",
    "    return result\n",
    "    \n",
    "%lprun -f run_analysis_v0 run_analysis_v0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a04df443-6860-466e-91df-5dd4a8230446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: app_v0.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    10   54.812 MiB   54.812 MiB           1   @profile\n",
      "    11                                         def run_analysis_v0():\n",
      "    12                                             # Load Data\n",
      "    13   54.812 MiB    0.000 MiB           1       gdp = {}\n",
      "    14   54.812 MiB    0.000 MiB           1       path = 'gdp_panel.csv'\n",
      "    15   68.703 MiB    0.000 MiB           2       with open(path) as f:\n",
      "    16   54.812 MiB    0.000 MiB           1           reader = csv.DictReader(f)\n",
      "    17   68.703 MiB    0.156 MiB      359997           for row in reader:\n",
      "    18   68.703 MiB    0.000 MiB      359996               country = row['code']\n",
      "    19   68.703 MiB    0.016 MiB      359996               value = float(row['value'])\n",
      "    20   68.703 MiB   11.000 MiB      359996               if country not in gdp:\n",
      "    21   68.672 MiB    0.000 MiB         189                   gdp[country] = []\n",
      "    22   68.703 MiB    2.719 MiB      359996               gdp[country].append(value)\n",
      "    23                                             \n",
      "    24   68.703 MiB    0.000 MiB           1       regions = {}\n",
      "    25   68.703 MiB    0.000 MiB           1       path = 'country_region.csv'\n",
      "    26   68.734 MiB    0.000 MiB           2       with open(path) as f:\n",
      "    27   68.703 MiB    0.000 MiB           1           reader = csv.DictReader(f)\n",
      "    28   68.734 MiB    0.031 MiB         272           for row in reader:\n",
      "    29   68.734 MiB    0.000 MiB         271               country = row['code']\n",
      "    30   68.734 MiB    0.000 MiB         271               region = row['region']\n",
      "    31   68.734 MiB    0.000 MiB         271               if country not in regions:\n",
      "    32   68.734 MiB    0.000 MiB         258                   regions[country] = region\n",
      "    33                                         \n",
      "    34                                             # Compute dgp growth rate and volitility\n",
      "    35   68.734 MiB    0.000 MiB           1       metrics = {}\n",
      "    36   68.734 MiB    0.000 MiB           1       window = 52\n",
      "    37   91.938 MiB -1130.266 MiB         190       for country, series in gdp.items():\n",
      "    38   91.938 MiB -1095.812 MiB         189           growth = []\n",
      "    39   91.938 MiB -1095.812 MiB         189           vol = []\n",
      "    40   92.016 MiB -1979433.500 MiB      350357           for i in range(window, len(series)):\n",
      "    41   92.016 MiB -1978305.719 MiB      350168               prev = series[i-window]\n",
      "    42   92.016 MiB -1978304.938 MiB      350168               curr = series[i]\n",
      "    43   92.016 MiB -1978301.969 MiB      350168               growth.append((curr - prev) / prev)\n",
      "    44   92.016 MiB -1978320.312 MiB      350168               vol.append(pstdev(series[i-window:i]))\n",
      "    45   91.938 MiB -1132.734 MiB         189           metrics[country] = {'growth': growth, 'vol': vol}\n",
      "    46                                         \n",
      "    47                                             # Aggregate Regions\n",
      "    48   57.484 MiB  -34.453 MiB           1       agg = {}  # plain dict\n",
      "    49                                         \n",
      "    50   83.656 MiB    0.000 MiB         190       for country, m in metrics.items():\n",
      "    51   83.656 MiB    0.000 MiB         189           region = regions[country]\n",
      "    52   83.656 MiB    0.000 MiB         189           if region not in agg:\n",
      "    53   58.406 MiB    0.000 MiB           6               agg[region] = {'growth': [], 'vol': []}\n",
      "    54   83.656 MiB   20.406 MiB         189           agg[region]['growth'].extend(m['growth'])\n",
      "    55   83.656 MiB    5.766 MiB         189           agg[region]['vol'].extend(m['vol'])\n",
      "    56                                             \n",
      "    57   83.656 MiB    0.000 MiB           1       result = {}\n",
      "    58   83.672 MiB    0.000 MiB           7       for region, d in agg.items():\n",
      "    59   83.672 MiB    0.000 MiB           6           total_growth = sum(d['growth'])\n",
      "    60   83.672 MiB    0.000 MiB           6           total_vol    = sum(d['vol'])\n",
      "    61   83.672 MiB    0.000 MiB           6           count_growth = len(d['growth'])\n",
      "    62   83.672 MiB    0.000 MiB           6           count_vol    = len(d['vol'])\n",
      "    63   83.672 MiB    0.016 MiB           6           result[region] = {\n",
      "    64   83.672 MiB    0.000 MiB           6               'avg_growth': total_growth / count_growth if count_growth else 0,\n",
      "    65   83.672 MiB    0.000 MiB           6               'avg_vol':    total_vol    / count_vol    if count_vol    else 0\n",
      "    66                                                 }\n",
      "    67   83.672 MiB    0.000 MiB           1       return result\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!\"{sys.executable}\" -m memory_profiler app_v0.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356b21fb-3597-49d6-b322-e1bfe504f331",
   "metadata": {},
   "source": [
    "## 3. Panda Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488baaa0-973d-4723-ba74-abb762cd8417",
   "metadata": {},
   "source": [
    "### 3.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d37ce5a2-713d-4be0-a0e4-a5de7e2c0264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>year</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2002-01-06</td>\n",
       "      <td>235.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2002-01-13</td>\n",
       "      <td>235.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2002-01-20</td>\n",
       "      <td>235.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2002-01-27</td>\n",
       "      <td>235.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AFG</td>\n",
       "      <td>2002-02-03</td>\n",
       "      <td>235.731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code       year    value\n",
       "0  AFG 2002-01-06  235.731\n",
       "1  AFG 2002-01-13  235.731\n",
       "2  AFG 2002-01-20  235.731\n",
       "3  AFG 2002-01-27  235.731\n",
       "4  AFG 2002-02-03  235.731"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "gdp = pd.read_csv(\n",
    "    'gdp_panel.csv',\n",
    "    usecols=['code','year','value'], \n",
    "    parse_dates=['year'],\n",
    "    dtype={'code':'category'}\n",
    ").sort_values(['code','year'])\n",
    "\n",
    "gdp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8c34fd79-f511-4261-a152-a5fda5b53d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ABW</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AFG</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AGO</td>\n",
       "      <td>Africa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AIA</td>\n",
       "      <td>North America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALA</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code         region\n",
       "11  ABW  North America\n",
       "0   AFG           Asia\n",
       "6   AGO         Africa\n",
       "7   AIA  North America\n",
       "1   ALA         Europe"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions = pd.read_csv(\n",
    "    'country_region.csv',\n",
    "    usecols=['code','region'], \n",
    "    dtype={'code':'category', 'region':'category'}\n",
    ").sort_values(['code'])\n",
    "\n",
    "regions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4805ede0-8c0f-47a0-823a-d252437c0d16",
   "metadata": {},
   "source": [
    "### 3.2 Compute GDP Growth and Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f94f23d7-ff86-41e5-8b43-6a6ff884d760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(350168, 5)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 52\n",
    "# pivot to wide form: rows=date, cols=country\n",
    "panel = gdp.pivot(index='year', columns='code', values='value')\n",
    "\n",
    "# rolling growth: pct_change over window periods\n",
    "growth = panel.pct_change(periods=window, fill_method=None)\n",
    "\n",
    "# rolling volatility: std over window periods\n",
    "vol = panel.rolling(window=window).std()\n",
    "\n",
    "# melt back to long form & merge region info\n",
    "growth = growth.stack().rename('growth').reset_index()\n",
    "vol    = vol.stack().rename('vol').reset_index()\n",
    "metrics = pd.merge(growth, vol, on=['year','code'])\n",
    "metrics = metrics.merge(regions, on='code')\n",
    "\n",
    "metrics.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9bc642-97fa-4bad-9bd7-43daeda0b46e",
   "metadata": {},
   "source": [
    "### 3.3 Aggregate Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9194a2dc-5d2b-4ee4-a94a-b765aa448a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               avg_growth      avg_vol\n",
      "region                                \n",
      "Africa           0.034585    39.550944\n",
      "Asia             0.043305  2599.704445\n",
      "Europe           0.019034    33.532537\n",
      "North America    0.025704     8.375173\n",
      "Oceania          0.019068     0.879407\n",
      "South America    0.026982   332.188656\n"
     ]
    }
   ],
   "source": [
    "result = (\n",
    "    metrics\n",
    "    .groupby(['region'], observed=False)\n",
    "    .agg(avg_growth=('growth','mean'),\n",
    "         avg_vol=('vol','mean'))\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2908ed5-e3fc-4b63-be93-e0f732c09ebb",
   "metadata": {},
   "source": [
    "### 3.4 Time and Memory Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2dd2c346-1b4b-4059-8d41-2304d28d3321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 0.526235 s\n",
       "File: /var/folders/j4/72zz472s4sdd1r1ssyml8k5w0000gn/T/ipykernel_30612/3883623108.py\n",
       "Function: run_analysis_v1 at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def run_analysis_v1():\n",
       "     2                                               # Load Data\n",
       "     3         3  448159000.0    1e+08     85.2      gdp = pd.read_csv(\n",
       "     4         1          0.0      0.0      0.0          'gdp_panel.csv',\n",
       "     5         1          0.0      0.0      0.0          usecols=['code','year','value'], # Only read necessary columns\n",
       "     6         1          0.0      0.0      0.0          parse_dates=['year'],\n",
       "     7         1       1000.0   1000.0      0.0          dtype={'code':'category'}\n",
       "     8         1    3727000.0    4e+06      0.7      ).sort_values(['code','year'])\n",
       "     9                                           \n",
       "    10         3    2109000.0 703000.0      0.4      regions = pd.read_csv(\n",
       "    11         1          0.0      0.0      0.0          'country_region.csv',\n",
       "    12         1       1000.0   1000.0      0.0          usecols=['code','region'], # Only read necessary columns\n",
       "    13         1          0.0      0.0      0.0          dtype={'code':'category', 'region':'category'}\n",
       "    14         1     170000.0 170000.0      0.0      ).sort_values(['code'])\n",
       "    15                                           \n",
       "    16         1          0.0      0.0      0.0      window = 52\n",
       "    17                                               # Compute GDP Growth and Volatility\n",
       "    18                                               # pivot to wide form: rows=date, cols=country\n",
       "    19         1   23322000.0    2e+07      4.4      panel = gdp.pivot(index='year', columns='code', values='value')\n",
       "    20                                           \n",
       "    21                                               # rolling growth: pct_change over window periods\n",
       "    22         1     789000.0 789000.0      0.1      growth = panel.pct_change(periods=window, fill_method=None)\n",
       "    23                                           \n",
       "    24                                               # rolling volatility: std over window periods\n",
       "    25         1    7985000.0    8e+06      1.5      vol = panel.rolling(window=window).std()\n",
       "    26                                           \n",
       "    27                                               # melt back to long form & merge region info\n",
       "    28         1    2849000.0    3e+06      0.5      growth = growth.stack().rename('growth').reset_index()\n",
       "    29         1    2829000.0    3e+06      0.5      vol    = vol.stack().rename('vol').reset_index()\n",
       "    30         1   17006000.0    2e+07      3.2      metrics = pd.merge(growth, vol, on=['year','code'])\n",
       "    31         1   14066000.0    1e+07      2.7      metrics = metrics.merge(regions, on='code')\n",
       "    32                                           \n",
       "    33                                               # Aggregate Regions\n",
       "    34         1          0.0      0.0      0.0      result = (\n",
       "    35         1          0.0      0.0      0.0          metrics\n",
       "    36         1     108000.0 108000.0      0.0          .groupby(['region'], observed=False)\n",
       "    37         2    3112000.0    2e+06      0.6          .agg(avg_growth=('growth','mean'),\n",
       "    38         1       1000.0   1000.0      0.0               avg_vol=('vol','mean'))\n",
       "    39                                               )\n",
       "    40         1       1000.0   1000.0      0.0      return result"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_analysis_v1():\n",
    "    # Load Data\n",
    "    gdp = pd.read_csv(\n",
    "        'gdp_panel.csv',\n",
    "        usecols=['code','year','value'], # Only read necessary columns\n",
    "        parse_dates=['year'],\n",
    "        dtype={'code':'category'}\n",
    "    ).sort_values(['code','year'])\n",
    "\n",
    "    regions = pd.read_csv(\n",
    "        'country_region.csv',\n",
    "        usecols=['code','region'], # Only read necessary columns\n",
    "        dtype={'code':'category', 'region':'category'}\n",
    "    ).sort_values(['code'])\n",
    "\n",
    "    window = 52\n",
    "    # Compute GDP Growth and Volatility\n",
    "    # pivot to wide form: rows=date, cols=country\n",
    "    panel = gdp.pivot(index='year', columns='code', values='value')\n",
    "    \n",
    "    # rolling growth: pct_change over window periods\n",
    "    growth = panel.pct_change(periods=window, fill_method=None)\n",
    "    \n",
    "    # rolling volatility: std over window periods\n",
    "    vol = panel.rolling(window=window).std()\n",
    "    \n",
    "    # melt back to long form & merge region info\n",
    "    growth = growth.stack().rename('growth').reset_index()\n",
    "    vol    = vol.stack().rename('vol').reset_index()\n",
    "    metrics = pd.merge(growth, vol, on=['year','code'])\n",
    "    metrics = metrics.merge(regions, on='code')\n",
    "\n",
    "    # Aggregate Regions\n",
    "    result = (\n",
    "        metrics\n",
    "        .groupby(['region'], observed=False)\n",
    "        .agg(avg_growth=('growth','mean'),\n",
    "             avg_vol=('vol','mean'))\n",
    "    )\n",
    "    return result\n",
    "\n",
    "%lprun -f run_analysis_v1 run_analysis_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b59b247b-bc0f-429d-a9c5-8f531046a96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: app_v1.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     9  121.172 MiB  121.172 MiB           1   @profile\n",
      "    10                                         def run_analysis_v1():\n",
      "    11                                             # Load Data\n",
      "    12  192.031 MiB   59.484 MiB           3       gdp = pd.read_csv(\n",
      "    13  121.172 MiB    0.000 MiB           1           'gdp_panel.csv',\n",
      "    14  121.172 MiB    0.000 MiB           1           usecols=['code','year','value'], # Only read necessary columns\n",
      "    15  121.172 MiB    0.000 MiB           1           parse_dates=['year'],\n",
      "    16  121.172 MiB    0.000 MiB           1           dtype={'code':'category'}\n",
      "    17  192.031 MiB   11.375 MiB           1       ).sort_values(['code','year'])\n",
      "    18                                         \n",
      "    19  192.109 MiB    0.062 MiB           3       regions = pd.read_csv(\n",
      "    20  192.031 MiB    0.000 MiB           1           'country_region.csv',\n",
      "    21  192.031 MiB    0.000 MiB           1           usecols=['code','region'], # Only read necessary columns\n",
      "    22  192.031 MiB    0.000 MiB           1           dtype={'code':'category', 'region':'category'}\n",
      "    23  192.109 MiB    0.016 MiB           1       ).sort_values(['code'])\n",
      "    24                                         \n",
      "    25  192.109 MiB    0.000 MiB           1       window = 52\n",
      "    26                                             # Compute GDP Growth and Volatility\n",
      "    27                                             # pivot to wide form: rows=date, cols=country\n",
      "    28  226.219 MiB   34.109 MiB           1       panel = gdp.pivot(index='year', columns='code', values='value')\n",
      "    29                                             \n",
      "    30                                             # rolling growth: pct_change over window periods\n",
      "    31  226.266 MiB    0.047 MiB           1       growth = panel.pct_change(periods=window, fill_method=None)\n",
      "    32                                             \n",
      "    33                                             # rolling volatility: std over window periods\n",
      "    34  229.438 MiB    3.172 MiB           1       vol = panel.rolling(window=window).std()\n",
      "    35                                             \n",
      "    36                                             # melt back to long form & merge region info\n",
      "    37  229.438 MiB    0.000 MiB           1       growth = growth.stack().rename('growth').reset_index()\n",
      "    38  229.453 MiB    0.016 MiB           1       vol    = vol.stack().rename('vol').reset_index()\n",
      "    39  271.000 MiB   41.547 MiB           1       metrics = pd.merge(growth, vol, on=['year','code'])\n",
      "    40  271.094 MiB    0.094 MiB           1       metrics = metrics.merge(regions, on='code')\n",
      "    41                                         \n",
      "    42                                             # Aggregate Regions\n",
      "    43  271.328 MiB    0.000 MiB           1       result = (\n",
      "    44  271.094 MiB    0.000 MiB           1           metrics\n",
      "    45  271.094 MiB    0.000 MiB           1           .groupby(['region'], observed=False)\n",
      "    46  271.328 MiB    0.234 MiB           2           .agg(avg_growth=('growth','mean'),\n",
      "    47  271.094 MiB    0.000 MiB           1                avg_vol=('vol','mean'))\n",
      "    48                                             )\n",
      "    49  271.328 MiB    0.000 MiB           1       return result\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!\"{sys.executable}\" -m memory_profiler app_v1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781ab701-5ae9-4afb-93f7-0824494d43b1",
   "metadata": {},
   "source": [
    "## 4. Memory Bound -> Process by Chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8b854e-5f71-42b0-9f8c-99b17f6b88be",
   "metadata": {},
   "source": [
    "### 4.1 Prepare Parquet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "50bc92fd-064e-4f04-a551-4419596e0a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "# Read the raw CSV in parallel\n",
    "ddf = dd.read_csv(\n",
    "    'gdp_panel.csv',\n",
    "    usecols=['code','year','value'],\n",
    "    parse_dates=['year'],\n",
    "    dtype={'code':'str'}\n",
    ")\n",
    "\n",
    "# Write out as partitioned Parquet\n",
    "#    Here we partition by 'country' so that each country’s data lives in its own sub-folder.\n",
    "ddf.to_parquet(\n",
    "    'gdp_panel_parquet/',\n",
    "    engine='pyarrow',\n",
    "    write_index=False,         # drop the old CSV index\n",
    "    partition_on=['code'],  # creates subfolders country=AAA, country=BBB, …\n",
    "    compression='snappy'       # fast compression\n",
    ")\n",
    "\n",
    "# Read the raw CSV in parallel\n",
    "ddf_region = dd.read_csv(\n",
    "    'country_region.csv',\n",
    "    usecols=['code','region'],\n",
    "    dtype={'code':'str'}\n",
    ")\n",
    "\n",
    "# Write out as partitioned Parquet\n",
    "ddf_region.to_parquet(\n",
    "    'country_region_parquet/',\n",
    "    engine='pyarrow',\n",
    "    write_index=False,         # drop the old CSV index\n",
    "    partition_on=['code'],  # creates subfolders country=AAA, country=BBB, …\n",
    "    compression='snappy'       # fast compression\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9fac07-7ee6-4907-9b9f-cb7a6742b458",
   "metadata": {},
   "source": [
    "### 4.2 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2d869cae-054d-4217-bdd7-15addf93a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "ddf = dd.read_parquet(\n",
    "    'gdp_panel_parquet/',\n",
    "    columns=['code','year','value'],\n",
    "    engine='pyarrow'\n",
    ")\n",
    "\n",
    "regions = dd.read_parquet('country_region_parquet/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549b5ca1-6252-4b8a-9727-c208ca627a00",
   "metadata": {},
   "source": [
    "### 4.3 Compute GDP Growth and Volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fc2f4d6a-46fa-4a69-bfde-96f1e4dc4aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_country(df, window=52):\n",
    "    # If this slice is empty, return an empty DataFrame\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=['code','mean_growth','mean_vol'])\n",
    "\n",
    "    # Otherwise do the rolling stats\n",
    "    df = df.sort_values('year')\n",
    "    growth = df['value'].pct_change(periods=window, fill_method=None).mean()\n",
    "    vol    = df['value'].rolling(window=window).std().mean()\n",
    "    return pd.DataFrame({\n",
    "        'code':        [df['code'].iat[0]],\n",
    "        'mean_growth': [growth],\n",
    "        'mean_vol':    [vol]\n",
    "    })\n",
    "\n",
    "# Build a proper meta so Dask knows what comes back\n",
    "meta = pd.DataFrame({\n",
    "    'code':        pd.Series(dtype='object'),\n",
    "    'mean_growth': pd.Series(dtype='float64'),\n",
    "    'mean_vol':    pd.Series(dtype='float64'),\n",
    "})\n",
    "\n",
    "country_summaries = ddf.groupby('code', observed=True).apply(\n",
    "    summarize_country,\n",
    "    meta=meta\n",
    ")\n",
    "\n",
    "country_summaries = country_summaries.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8afbbb-9573-408c-9bf6-66f7e8a10c77",
   "metadata": {},
   "source": [
    "### 4.4 Aggregate Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0369a775-e38e-4303-90e4-ac54d4e7816c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_growth</th>\n",
       "      <th>mean_vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Africa</th>\n",
       "      <td>0.034808</td>\n",
       "      <td>37.397032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asia</th>\n",
       "      <td>0.043784</td>\n",
       "      <td>2325.302294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North America</th>\n",
       "      <td>0.025704</td>\n",
       "      <td>8.371062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Europe</th>\n",
       "      <td>0.019083</td>\n",
       "      <td>38.417443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South America</th>\n",
       "      <td>0.026982</td>\n",
       "      <td>332.025578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oceania</th>\n",
       "      <td>0.017529</td>\n",
       "      <td>0.754321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               mean_growth     mean_vol\n",
       "region                                 \n",
       "Africa            0.034808    37.397032\n",
       "Asia              0.043784  2325.302294\n",
       "North America     0.025704     8.371062\n",
       "Europe            0.019083    38.417443\n",
       "South America     0.026982   332.025578\n",
       "Oceania           0.017529     0.754321"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_summaries = country_summaries.astype({'code': 'string'})\n",
    "regions = regions.astype({'code': 'string'})\n",
    "\n",
    "country_summaries = country_summaries.merge(regions, on='code')\n",
    "\n",
    "regional_stats = (\n",
    "    country_summaries\n",
    "    .groupby('region', observed=True)[['mean_growth', 'mean_vol']]\n",
    "    .mean()\n",
    "    .compute()\n",
    ")\n",
    "\n",
    "regional_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a7d74b-125c-4050-9a99-70b2f2a306b1",
   "metadata": {},
   "source": [
    "### 4.5 Time and Memory Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e1d4f85d-e525-499e-bd44-a3c756dd7bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 2.49499 s\n",
       "File: /var/folders/j4/72zz472s4sdd1r1ssyml8k5w0000gn/T/ipykernel_30612/1602383827.py\n",
       "Function: run_analysis_v2 at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def run_analysis_v2():\n",
       "     2                                               # Load data\n",
       "     3         2   54152000.0    3e+07      2.2      ddf = dd.read_parquet(\n",
       "     4         1          0.0      0.0      0.0          'gdp_panel_parquet/',\n",
       "     5         1       1000.0   1000.0      0.0          columns=['code','year','value'],\n",
       "     6         1          0.0      0.0      0.0          engine='pyarrow'\n",
       "     7                                               )\n",
       "     8                                           \n",
       "     9         1   40865000.0    4e+07      1.6      regions = dd.read_parquet('country_region_parquet/')\n",
       "    10                                           \n",
       "    11                                               # Compute GDP Growth and Volatility\n",
       "    12         2     215000.0 107500.0      0.0      meta = pd.DataFrame({\n",
       "    13         1      82000.0  82000.0      0.0          'code':        pd.Series(dtype='object'),\n",
       "    14         1      43000.0  43000.0      0.0          'mean_growth': pd.Series(dtype='float64'),\n",
       "    15         1      36000.0  36000.0      0.0          'mean_vol':    pd.Series(dtype='float64'),\n",
       "    16                                               })\n",
       "    17                                           \n",
       "    18         2     418000.0 209000.0      0.0      country_summaries = ddf.groupby('code', observed=True).apply(\n",
       "    19         1       1000.0   1000.0      0.0          summarize_country,\n",
       "    20         1          0.0      0.0      0.0          meta=meta\n",
       "    21                                               )\n",
       "    22                                           \n",
       "    23         1      49000.0  49000.0      0.0      country_summaries = country_summaries.reset_index(drop=True)\n",
       "    24                                           \n",
       "    25                                               # Aggregate regions\n",
       "    26         1      33000.0  33000.0      0.0      country_summaries = country_summaries.astype({'code': 'string'})\n",
       "    27         1      27000.0  27000.0      0.0      regions = regions.astype({'code': 'string'})\n",
       "    28                                           \n",
       "    29         1     201000.0 201000.0      0.0      country_summaries = country_summaries.merge(regions, on='code')\n",
       "    30                                           \n",
       "    31         1       1000.0   1000.0      0.0      result = (\n",
       "    32         2     423000.0 211500.0      0.0          country_summaries\n",
       "    33         1      85000.0  85000.0      0.0          .groupby('region', observed=True)[['mean_growth', 'mean_vol']]\n",
       "    34         1    3003000.0    3e+06      0.1          .mean()\n",
       "    35         1 2395359000.0    2e+09     96.0          .compute()\n",
       "    36                                               )\n",
       "    37         1          0.0      0.0      0.0      return result"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_analysis_v2():\n",
    "    # Load data\n",
    "    ddf = dd.read_parquet(\n",
    "        'gdp_panel_parquet/',\n",
    "        columns=['code','year','value'],\n",
    "        engine='pyarrow'\n",
    "    )\n",
    "    \n",
    "    regions = dd.read_parquet('country_region_parquet/')\n",
    "\n",
    "    # Compute GDP Growth and Volatility\n",
    "    meta = pd.DataFrame({\n",
    "        'code':        pd.Series(dtype='object'),\n",
    "        'mean_growth': pd.Series(dtype='float64'),\n",
    "        'mean_vol':    pd.Series(dtype='float64'),\n",
    "    })\n",
    "    \n",
    "    country_summaries = ddf.groupby('code', observed=True).apply(\n",
    "        summarize_country,\n",
    "        meta=meta\n",
    "    )\n",
    "    \n",
    "    country_summaries = country_summaries.reset_index(drop=True)\n",
    "\n",
    "    # Aggregate regions\n",
    "    country_summaries = country_summaries.astype({'code': 'string'})\n",
    "    regions = regions.astype({'code': 'string'})\n",
    "    \n",
    "    country_summaries = country_summaries.merge(regions, on='code')\n",
    "    \n",
    "    result = (\n",
    "        country_summaries\n",
    "        .groupby('region', observed=True)[['mean_growth', 'mean_vol']]\n",
    "        .mean()\n",
    "        .compute()\n",
    "    )\n",
    "    return result\n",
    "\n",
    "%lprun -f run_analysis_v2 run_analysis_v2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dd8cf8eb-e945-4bd5-8f0d-368c4ecea1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: app_v2.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    25  158.516 MiB  158.516 MiB           1   @profile\n",
      "    26                                         def run_analysis_v2():\n",
      "    27                                             # Load data\n",
      "    28  164.500 MiB    5.984 MiB           2       ddf = dd.read_parquet(\n",
      "    29  158.516 MiB    0.000 MiB           1           'gdp_panel_parquet/',\n",
      "    30  158.516 MiB    0.000 MiB           1           columns=['code','year','value'],\n",
      "    31  158.516 MiB    0.000 MiB           1           engine='pyarrow'\n",
      "    32                                             )\n",
      "    33                                             \n",
      "    34  165.453 MiB    0.953 MiB           1       regions = dd.read_parquet('country_region_parquet/')\n",
      "    35                                         \n",
      "    36                                             # Compute GDP Growth and Volatility\n",
      "    37  165.453 MiB    0.000 MiB           2       meta = pd.DataFrame({\n",
      "    38  165.453 MiB    0.000 MiB           1           'code':        pd.Series(dtype='object'),\n",
      "    39  165.453 MiB    0.000 MiB           1           'mean_growth': pd.Series(dtype='float64'),\n",
      "    40  165.453 MiB    0.000 MiB           1           'mean_vol':    pd.Series(dtype='float64'),\n",
      "    41                                             })\n",
      "    42                                             \n",
      "    43  165.594 MiB    0.141 MiB           2       country_summaries = ddf.groupby('code', observed=True).apply(\n",
      "    44  165.578 MiB    0.000 MiB           1           summarize_country,\n",
      "    45  165.578 MiB    0.000 MiB           1           meta=meta\n",
      "    46                                             )\n",
      "    47                                             \n",
      "    48  165.594 MiB    0.000 MiB           1       country_summaries = country_summaries.reset_index(drop=True)\n",
      "    49                                         \n",
      "    50                                             # Aggregate regions\n",
      "    51  165.703 MiB    0.109 MiB           1       country_summaries = country_summaries.astype({'code': 'string'})\n",
      "    52  165.703 MiB    0.000 MiB           1       regions = regions.astype({'code': 'string'})\n",
      "    53                                             \n",
      "    54  166.234 MiB    0.531 MiB           1       country_summaries = country_summaries.merge(regions, on='code')\n",
      "    55                                             \n",
      "    56  224.938 MiB    0.000 MiB           1       result = (\n",
      "    57  166.266 MiB    0.031 MiB           2           country_summaries\n",
      "    58  166.234 MiB    0.000 MiB           1           .groupby('region', observed=True)[['mean_growth', 'mean_vol']]\n",
      "    59  166.969 MiB    0.703 MiB           1           .mean()\n",
      "    60  224.938 MiB   57.969 MiB           1           .compute()\n",
      "    61                                             )\n",
      "    62  224.938 MiB    0.000 MiB           1       return result\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!\"{sys.executable}\" -m memory_profiler app_v2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cef2683-d929-4ed4-929f-f5ec1f093990",
   "metadata": {},
   "source": [
    "## 5. CPU Bound -> Parallel Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3d092ce5-f913-40c7-ba55-c51702090d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7ab156-e24c-40f1-b95d-c4bb0013c982",
   "metadata": {},
   "source": [
    "### 5.1 Prepare Parquet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "50ff7846-0587-4d3c-85fd-c35d8ef24b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the raw CSV in parallel\n",
    "ddf = dd.read_csv(\n",
    "    'gdp_panel.csv',\n",
    "    usecols=['code','year','value'],\n",
    "    parse_dates=['year'],\n",
    "    dtype={'code':'str'}\n",
    ")\n",
    "\n",
    "# Write out as partitioned Parquet\n",
    "#    Here we partition by 'country' so that each country’s data lives in its own sub-folder.\n",
    "ddf.to_parquet(\n",
    "    'gdp_panel_parquet/',\n",
    "    engine='pyarrow',\n",
    "    write_index=False,         # drop the old CSV index\n",
    "    partition_on=['code'],  # creates subfolders country=AAA, country=BBB, …\n",
    "    compression='snappy'       # fast compression\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c85d0f5-7acb-478f-83ee-7f8edec2e8c9",
   "metadata": {},
   "source": [
    "### 5.2 Functions to Detect and Process Single Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f0eb2b5a-a986-4289-ba2b-e6d23a417d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_country_tasks(base_dir):\n",
    "    tasks = []\n",
    "    for entry in os.listdir(base_dir):\n",
    "        full = os.path.join(base_dir, entry)\n",
    "        if not (entry.startswith(\"code=\") and os.path.isdir(full)):\n",
    "            continue\n",
    "\n",
    "        code = entry.split(\"=\", 1)[1]\n",
    "        pattern = os.path.join(full, \"*.parquet\")\n",
    "        files = sorted(glob.glob(pattern))\n",
    "        if files:\n",
    "            tasks.append((code, files))\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d7faeeda-2fbb-43d1-ba95-f6c75a927ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_country(code, parquet_paths, window = 52):\n",
    "    # parquet_paths: list of all .parquet files for a single country-partition\n",
    "    # read them all (value only), concatenate into one 1-D numpy array\n",
    "    arrays = []\n",
    "    for path in parquet_paths:\n",
    "        tbl = pq.read_table(path, columns=['value'])\n",
    "        arrays.append(tbl.column('value').to_numpy())\n",
    "    series = np.concatenate(arrays)\n",
    "    # now do the window‐period rolling growth & vol\n",
    "    growth = (series[window:] - series[:-window]) / series[:-window]\n",
    "    windows = np.lib.stride_tricks.sliding_window_view(series, window)\n",
    "    vol    = np.std(windows, axis=1)\n",
    "    return code, (growth.mean(), vol.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2937638c-fa35-46ff-b76a-4c2388f449b0",
   "metadata": {},
   "source": [
    "### 5.3 Process Files in Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "8e9bd5be-e863-4b2e-ad0f-7b0d40befd4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BRN', ['gdp_panel_parquet/code=BRN/part.0.parquet']),\n",
       " ('AGO', ['gdp_panel_parquet/code=AGO/part.0.parquet']),\n",
       " ('GNB', ['gdp_panel_parquet/code=GNB/part.0.parquet']),\n",
       " ('OMN', ['gdp_panel_parquet/code=OMN/part.0.parquet']),\n",
       " ('MNE', ['gdp_panel_parquet/code=MNE/part.0.parquet'])]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Discover tasks\n",
    "tasks = discover_country_tasks('gdp_panel_parquet/')\n",
    "tasks[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f482b534-a7a7-4736-8ae7-d3bee3967a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Client: 'tcp://127.0.0.1:52985' processes=5 threads=10, memory=16.00 GiB>\n"
     ]
    }
   ],
   "source": [
    "# Launch Dask\n",
    "client = Client() \n",
    "print(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2e754465-0971-44a4-8296-23781386e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit tasks\n",
    "futures = client.map(lambda args: process_country(*args), tasks)\n",
    "results = client.gather(futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b0e08505-9cfa-4ce2-b006-dec1b6a17be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close Dask\n",
    "client.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "46c8f6b1-1e6d-47ad-a51d-15032c176b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DataFrame & merge\n",
    "df = pd.DataFrame(\n",
    "    [(code, g, v) for code, (g, v) in results],\n",
    "    columns=['code','avg_growth','avg_vol']\n",
    ")\n",
    "regions = pd.read_csv('country_region.csv', dtype={\"code\": str})\n",
    "df = df.merge(regions, on=\"code\", how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0106e3f6-3706-45a4-8ac8-aa9e97073379",
   "metadata": {},
   "source": [
    "### 5.4 Aggregate Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d1d7cb45-c3bc-45d1-9929-b71d80a91c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_growth</th>\n",
       "      <th>avg_vol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Africa</th>\n",
       "      <td>0.034808</td>\n",
       "      <td>37.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asia</th>\n",
       "      <td>0.043784</td>\n",
       "      <td>2302.835078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Europe</th>\n",
       "      <td>0.019083</td>\n",
       "      <td>38.046251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>North America</th>\n",
       "      <td>0.025704</td>\n",
       "      <td>8.290180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oceania</th>\n",
       "      <td>0.017529</td>\n",
       "      <td>0.747032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South America</th>\n",
       "      <td>0.026982</td>\n",
       "      <td>328.817527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               avg_growth      avg_vol\n",
       "region                                \n",
       "Africa           0.034808    37.035700\n",
       "Asia             0.043784  2302.835078\n",
       "Europe           0.019083    38.046251\n",
       "North America    0.025704     8.290180\n",
       "Oceania          0.017529     0.747032\n",
       "South America    0.026982   328.817527"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate by region\n",
    "result = df.groupby(\"region\")[[\"avg_growth\", \"avg_vol\"]].mean()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba74c825-084c-4490-8eb0-783033afd5d2",
   "metadata": {},
   "source": [
    "### 5.5 Time and Memory Profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8c42d85d-ea08-4ae9-8fc0-7da8a3d5423b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timer unit: 1e-09 s\n",
       "\n",
       "Total time: 1.02506 s\n",
       "File: /var/folders/j4/72zz472s4sdd1r1ssyml8k5w0000gn/T/ipykernel_30612/188904422.py\n",
       "Function: run_analysis_v3 at line 1\n",
       "\n",
       "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
       "==============================================================\n",
       "     1                                           def run_analysis_v3():\n",
       "     2                                               # Discover tasks\n",
       "     3         1   38320000.0    4e+07      3.7      tasks = discover_country_tasks('gdp_panel_parquet/')\n",
       "     4                                           \n",
       "     5                                               # Launch Dask\n",
       "     6         1  454413000.0    5e+08     44.3      client = Client() \n",
       "     7                                           \n",
       "     8                                               # Submit Tasks\n",
       "     9         1    7538000.0    8e+06      0.7      futures = client.map(lambda args: process_country(*args), tasks)\n",
       "    10         1  398899000.0    4e+08     38.9      results = client.gather(futures)\n",
       "    11                                           \n",
       "    12                                               # Close Dask\n",
       "    13         1  122059000.0    1e+08     11.9      client.close() \n",
       "    14                                           \n",
       "    15                                               # Build DataFrame & merge\n",
       "    16         2     521000.0 260500.0      0.1      df = pd.DataFrame(\n",
       "    17       190      43000.0    226.3      0.0          [(code, g, v) for code, (g, v) in results],\n",
       "    18         1          0.0      0.0      0.0          columns=['code','avg_growth','avg_vol']\n",
       "    19                                               )\n",
       "    20         1    1598000.0    2e+06      0.2      regions = pd.read_csv('country_region.csv', dtype={\"code\": str})\n",
       "    21         1    1041000.0    1e+06      0.1      df = df.merge(regions, on=\"code\", how=\"left\")\n",
       "    22                                           \n",
       "    23                                               # Aggregate by region\n",
       "    24         1     630000.0 630000.0      0.1      result = df.groupby(\"region\")[[\"avg_growth\", \"avg_vol\"]].mean()\n",
       "    25                                           \n",
       "    26         1       1000.0   1000.0      0.0      return result"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def run_analysis_v3():\n",
    "    # Discover tasks\n",
    "    tasks = discover_country_tasks('gdp_panel_parquet/')\n",
    "\n",
    "    # Launch Dask\n",
    "    client = Client() \n",
    "\n",
    "    # Submit Tasks\n",
    "    futures = client.map(lambda args: process_country(*args), tasks)\n",
    "    results = client.gather(futures)\n",
    "\n",
    "    # Close Dask\n",
    "    client.close() \n",
    "\n",
    "    # Build DataFrame & merge\n",
    "    df = pd.DataFrame(\n",
    "        [(code, g, v) for code, (g, v) in results],\n",
    "        columns=['code','avg_growth','avg_vol']\n",
    "    )\n",
    "    regions = pd.read_csv('country_region.csv', dtype={\"code\": str})\n",
    "    df = df.merge(regions, on=\"code\", how=\"left\")\n",
    "\n",
    "    # Aggregate by region\n",
    "    result = df.groupby(\"region\")[[\"avg_growth\", \"avg_vol\"]].mean()\n",
    "\n",
    "    return result\n",
    "\n",
    "%lprun -f run_analysis_v3 run_analysis_v3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "add2cbfd-a1f3-455a-8d94-fae61eaf202a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: app_v3.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    42  139.344 MiB  139.344 MiB           1   @profile\n",
      "    43                                         def run_analysis_v3():\n",
      "    44                                             # Discover tasks\n",
      "    45  139.406 MiB    0.062 MiB           1       tasks = discover_country_tasks('gdp_panel_parquet/')\n",
      "    46                                         \n",
      "    47                                             # Launch Dask\n",
      "    48  144.125 MiB    4.719 MiB           1       client = Client() \n",
      "    49                                         \n",
      "    50                                             # Submit Tasks\n",
      "    51  144.312 MiB    0.188 MiB           1       futures = client.map(lambda args: process_country(*args), tasks)\n",
      "    52  146.766 MiB    2.453 MiB           1       results = client.gather(futures)\n",
      "    53                                         \n",
      "    54                                             # Close Dask\n",
      "    55  146.281 MiB   -0.484 MiB           1       client.close() \n",
      "    56                                         \n",
      "    57                                             # Build DataFrame & merge\n",
      "    58  146.469 MiB    0.188 MiB           2       df = pd.DataFrame(\n",
      "    59  146.281 MiB    0.000 MiB         190           [(code, g, v) for code, (g, v) in results],\n",
      "    60  146.281 MiB    0.000 MiB           1           columns=['code','avg_growth','avg_vol']\n",
      "    61                                             )\n",
      "    62  146.750 MiB    0.281 MiB           1       regions = pd.read_csv('country_region.csv', dtype={\"code\": str})\n",
      "    63  147.344 MiB    0.594 MiB           1       df = df.merge(regions, on=\"code\", how=\"left\")\n",
      "    64                                         \n",
      "    65                                             # Aggregate by region\n",
      "    66  147.578 MiB    0.234 MiB           1       result = df.groupby(\"region\")[[\"avg_growth\", \"avg_vol\"]].mean()\n",
      "    67                                         \n",
      "    68  147.578 MiB    0.000 MiB           1       return result\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!\"{sys.executable}\" -m memory_profiler app_v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed6c9e-06fd-4cd0-813f-f81e6f208012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
